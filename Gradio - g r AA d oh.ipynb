{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38deebae",
   "metadata": {},
   "source": [
    "## Gradio\n",
    "* Python library that allows you to rapidly create **UIs** for ML/DL models and thus gaining popularity in ML/DL communities for its ability to **simplify the development of interactive and user-friendly ML/DL application**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9f0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in MarkupSafe:2.1.0, they have removed soft_unicode, try using:\n",
    "# !pip install markupsafe==2.0.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae5fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1374205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a14686",
   "metadata": {},
   "source": [
    "### <u>Example1:<u>\n",
    "#### with a simple \"Hello, World\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66de19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b392427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60517336",
   "metadata": {},
   "source": [
    "**gr.Interface** : This Interface class can wrap any Python function with a user interface.\n",
    "    The core Interface class is initialized with three required parameters:\n",
    "\n",
    "* fn: the function to wrap a UI around\n",
    "* inputs: which component(s) to use for the input (e.g. \"text\", \"image\" or \"audio\")\n",
    "* outputs: which component(s) to use for the output (e.g. \"text\", \"image\" or \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbf5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566c39ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58824591",
   "metadata": {},
   "source": [
    "### <u>Example 2<u>:\n",
    "#### Multiple Input and Output Components - Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401e90e",
   "metadata": {},
   "source": [
    "#### Step 1: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfe862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ec593",
   "metadata": {},
   "source": [
    "#### Step 2: Load a pre-trained image classification model (e.g., MobileNetV2 from TensorFlow)\n",
    "The model is a pre-trained **MobileNetV2 for image classification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f129707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6905eaf",
   "metadata": {},
   "source": [
    "#### Step 3: Define a function to preprocess the image for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28727e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(input_image):\n",
    "    input_image = Image.fromarray(input_image.astype('uint8'))\n",
    "    input_image = input_image.resize((224, 224))\n",
    "    input_image = tf.keras.preprocessing.image.img_to_array(input_image)\n",
    "    input_image = tf.keras.applications.mobilenet_v2.preprocess_input(input_image)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddc2b8",
   "metadata": {},
   "source": [
    "#### Step4: Define a function to make predictions using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c114bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(input_image, additional_comment):\n",
    "    preprocessed_image = preprocess_image(input_image)\n",
    "    expanded_image = tf.expand_dims(preprocessed_image, axis=0)\n",
    "    predictions = model.predict(expanded_image)\n",
    "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions)[0]\n",
    "    top_predictions = [f\"{label}: {cls} ({prob:.2f})\" for (label, cls, prob) in decoded_predictions[:3]]\n",
    "    return top_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbe190",
   "metadata": {},
   "source": [
    "* Note: The classify_image function takes an input image, preprocesses it, and returns the top three predictions along with their probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74cbdb",
   "metadata": {},
   "source": [
    "#### Step5: Define Gradio interfaces with multiple input and output components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302c0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(fn=classify_image,\n",
    "                     inputs=[gr.Image(type=\"numpy\", label=\"Input Image\"),\"text\"]  # Additional input component for the user to provide comments\n",
    "                    ,outputs=\"text\"  # Display top predictions as text\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2335f54",
   "metadata": {},
   "source": [
    "* Note: The Gradio interface is created with two input components (an image and text) and three output components (labels for the top three predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1e0e8",
   "metadata": {},
   "source": [
    "#### Step 6: Launch the Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee54f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076be79",
   "metadata": {},
   "source": [
    "### <u>Example 3<u>:\n",
    "#### Multiple Input and Output Components - Sentiment Analysis (Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a8836",
   "metadata": {},
   "source": [
    "* We use the Hugging Face transformers library to load a pre-trained sentiment analysis model.\n",
    "* The analyze_sentiment function takes a text input, uses the model to analyze sentiment, and returns the sentiment label along with confidence.\n",
    "* The Gradio interface is created with a single text input and a text output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e24eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cc482",
   "metadata": {},
   "source": [
    "#### Step 1: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed866ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd0061",
   "metadata": {},
   "source": [
    "#### Step 2: Load a pre-trained sentiment analysis model using transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33351df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269a9b0",
   "metadata": {},
   "source": [
    "#### Step3: Define a function to perform sentiment analysis on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8ce037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text_input):\n",
    "    result = sentiment_model(text_input)\n",
    "    sentiment = result[0]['label']\n",
    "    confidence = result[0]['score']\n",
    "    return f\"Sentiment: {sentiment} (Confidence: {confidence:.2f})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6d6e9",
   "metadata": {},
   "source": [
    "#### Step 4: Define Gradio interface with a text input and a text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d1d273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=analyze_sentiment,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad57ade",
   "metadata": {},
   "source": [
    "#### Step 5: Launch the Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b17db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c381e11",
   "metadata": {},
   "source": [
    "**Note:** Here the top predictions are combined into a list of strings, and the output component is specified as \"text\" to display the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
